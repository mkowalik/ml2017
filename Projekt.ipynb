{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projekt zaliczeniowy\n",
    "\n",
    "Link do submisji: wkrótce\n",
    "\n",
    "Uwaga: Jeśli ktoś robi własny projekt (grupy Staszka) to wystarczy wysłać kod oraz rozszerzony opis.\n",
    "\n",
    "Tymczasowy link do danych: https://drive.google.com/drive/folders/0BwExETCslterV0E1aXVObUlVUGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opis projektu\n",
    "\n",
    "Projekt polega na wytrenowaniu klasyfikatora kolorowych obrazków na datasecie [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "Zestaw danych wygląda następująco:\n",
    "* X_train - zbiór treningowy - cechy (piksele, 3 kanały kolorów),\n",
    "* y_train - etykiety X_train (0-9),\n",
    "* X_train_small - losowy podzbiór X_train (10%),\n",
    "* y_train_small - etykiety X_train_small,\n",
    "* X_test - zbiór testowy, na którym należy obliczyć predykcje.\n",
    "\n",
    "Tabelę y_test (etykiety zbioru testowego) można odnaleźć w internecie, ale proszę tego **nie** robić.\n",
    "\n",
    "Pojedynczy wiersz tabelach X to wektor długości 3072, czterowymiarową macierz obrazków możemy uzyskać stosując metodę X.reshape(-1,3,32,32). Dane w tabelach X są intami - przed uczeniem należy je zrzutować na floaty. \n",
    "\n",
    "#### Część pierwsza - całość CIFAR-10\n",
    "\n",
    "Dane, których można używać: X_train, y_train, X_test.\n",
    "\n",
    "Model należy wytrenować na parze (X_train, y_train), a następnie przeliczyć i zasubmitować predykcje na X_test.\n",
    "\n",
    "#### Część druga - subset CIFAR-10\n",
    "\n",
    "Danie, których można używać: X_train, X_train_small, y_train_small, X_test.\n",
    "\n",
    "**Nie** można używać tabeli y_train.\n",
    "\n",
    "\n",
    "Model należy wytrenować unsupervised (pretraining / uczenie reprezentacji) na zbiorze X_train, a następnie kontynuować uczenie supervised na parze (X_train_small, y_train_small) i zasubmitować predykcję na X_test. Wynik trzeba porównać z wynikiem modelu nauczonego z pominięciem trenowania unsupervised.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punktacja\n",
    "\n",
    "Liczba punktów za projekt podana jest w ogłoszeniach i różni się pomiędzy grupami ćwiczeniowymi.\n",
    "\n",
    "Na rozwiązanie projektu składa się sześć jednakowo ocenianych części:\n",
    "\n",
    "(CIFAR-10 - całość)\n",
    "* opis przetestowanych modelów (w tym opcjonalnie preprocessing danych) - na czym w skrócie polega zasada ich działania, w jaki sposób są one w stanie dobrze klasyfikować obrazki,\n",
    "* opis działania hiperparametrów, algorytm doboru hiperparametrów - za co odpowiadają poszczególne hiperparametry używanych modelów, jak dobrano najlepszy zestaw,\n",
    "* przebicie 40% accuracy,\n",
    "* przebicie 60% accuracy (hint: prosta sieć konwolucyjna),\n",
    "\n",
    "(CIFAR-10 - subset)\n",
    "* zastosowanie unsupervised pretrainingu na dużym zbiorze CIFAR-10, uczenie nadzorowane na subsecie - opis działania użytego pretrainingu, porównanie ze skutecznością takiego samego modelu, ale uczonego bez pretrainingu lub z pretrainingiem na zbiorze \"subset\",\n",
    "* przebicie 50% accuracy.\n",
    "\n",
    "\n",
    "Rozwiązania, w których najlepszy zestaw hiperparametrów został \"odgadnięty\", dobrany ręcznie itp. będą ocenione w całości na zero punktów.\n",
    "\n",
    "Rozwiązania, w których podczas uczenia używano danych ze zbioru testowego będą ocenione w całości na zero punktów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Baseline dla zbioru CIFAR-10 - regresja logistyczna w wersji multiclass\n",
    "# Przy submitowaniu predykcji proszę używać funkcji save_labels\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def save_labels(arr, filename):\n",
    "    pd_array = pd.DataFrame(arr)\n",
    "    pd_array.index.names = [\"Id\"]\n",
    "    pd_array.columns = [\"Prediction\"]\n",
    "    pd_array.to_csv(filename)\n",
    "\n",
    "def load_labels(filename):\n",
    "    return pd.read_csv(filename, index_col=0).values.ravel()\n",
    "\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "y_train = load_labels(\"y_train.csv\")\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "\n",
    "if not os.path.isfile(\"baseline.pkl\"):\n",
    "    lr = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(verbose=43))])\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(\"Train acc:\", accuracy_score(y_train, lr.predict(X_train)))\n",
    "    with open(\"baseline.pkl\", 'w') as f_out:\n",
    "        pickle.dump(lr, f_out)\n",
    "else:\n",
    "    with open(\"baseline.pkl\", 'r') as f_in:\n",
    "        lr = pickle.load(f_in)\n",
    "\n",
    "save_labels(model.predict(X_test), \"y_pred.csv\")\n",
    "\n",
    "# Train acc: 0.52238\n",
    "# Test acc: 0.3703\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
