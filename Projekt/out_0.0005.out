Using TensorFlow backend.
(50000, 3072)
(10000, 3072)
(5000, 3072)
9
0
10
Start converting data!
(3750, 32, 32, 3)
(1250, 32, 32, 3)
(3750, 10)
(1250, 10)
10
(50000, 32, 32, 3)
Converting data done!
10
Training network on: 
kernel size: (3, 3)
lrate:       0.0005
dropout:     0.2
dense size:  1024
Running Fold 1 / 2
Train on 33330 samples, validate on 16670 samples
Epoch 1/75
2017-06-18 02:28:00.446096: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.446115: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.446120: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.446123: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.446126: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.554759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-18 02:28:00.555178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 750 Ti
major: 5 minor: 0 memoryClockRate (GHz) 1.202
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 3.70GiB
2017-06-18 02:28:00.555192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-18 02:28:00.555196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-18 02:28:00.555202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0)
24s - loss: 1.9831 - acc: 0.2929 - val_loss: 1.8252 - val_acc: 0.3696
Epoch 2/75
23s - loss: 1.7553 - acc: 0.3804 - val_loss: 1.7001 - val_acc: 0.4095
Epoch 3/75
23s - loss: 1.6479 - acc: 0.4195 - val_loss: 1.6288 - val_acc: 0.4317
Epoch 4/75
23s - loss: 1.5632 - acc: 0.4496 - val_loss: 1.5326 - val_acc: 0.4637
Epoch 5/75
23s - loss: 1.5065 - acc: 0.4685 - val_loss: 1.4958 - val_acc: 0.4783
Epoch 6/75
23s - loss: 1.4548 - acc: 0.4872 - val_loss: 1.4654 - val_acc: 0.4875
Epoch 7/75
23s - loss: 1.4082 - acc: 0.5050 - val_loss: 1.4305 - val_acc: 0.5050
Epoch 8/75
23s - loss: 1.3652 - acc: 0.5177 - val_loss: 1.4065 - val_acc: 0.5107
Epoch 9/75
23s - loss: 1.3186 - acc: 0.5363 - val_loss: 1.3554 - val_acc: 0.5258
Epoch 10/75
23s - loss: 1.2777 - acc: 0.5493 - val_loss: 1.3107 - val_acc: 0.5413
Epoch 11/75
23s - loss: 1.2413 - acc: 0.5629 - val_loss: 1.2939 - val_acc: 0.5424
Epoch 12/75
23s - loss: 1.2050 - acc: 0.5716 - val_loss: 1.2813 - val_acc: 0.5509
Epoch 13/75
23s - loss: 1.1689 - acc: 0.5872 - val_loss: 1.2775 - val_acc: 0.5527
Epoch 14/75
23s - loss: 1.1368 - acc: 0.5994 - val_loss: 1.2446 - val_acc: 0.5614
Epoch 15/75
23s - loss: 1.1035 - acc: 0.6127 - val_loss: 1.2291 - val_acc: 0.5693
Epoch 16/75
23s - loss: 1.0730 - acc: 0.6218 - val_loss: 1.2246 - val_acc: 0.5662
Epoch 17/75
23s - loss: 1.0386 - acc: 0.6338 - val_loss: 1.2198 - val_acc: 0.5728
Epoch 18/75
23s - loss: 1.0043 - acc: 0.6475 - val_loss: 1.1921 - val_acc: 0.5804
Epoch 19/75
23s - loss: 0.9723 - acc: 0.6599 - val_loss: 1.1789 - val_acc: 0.5879
Epoch 20/75
23s - loss: 0.9333 - acc: 0.6713 - val_loss: 1.1757 - val_acc: 0.5873
Epoch 21/75
23s - loss: 0.9036 - acc: 0.6818 - val_loss: 1.1841 - val_acc: 0.5887
Epoch 22/75
23s - loss: 0.8686 - acc: 0.6973 - val_loss: 1.1598 - val_acc: 0.6016
Epoch 23/75
23s - loss: 0.8332 - acc: 0.7097 - val_loss: 1.1822 - val_acc: 0.5897
Epoch 24/75
23s - loss: 0.7993 - acc: 0.7201 - val_loss: 1.1761 - val_acc: 0.5977
Epoch 25/75
23s - loss: 0.7636 - acc: 0.7307 - val_loss: 1.1722 - val_acc: 0.6013
Epoch 26/75
23s - loss: 0.7273 - acc: 0.7477 - val_loss: 1.1501 - val_acc: 0.6073
Epoch 27/75
23s - loss: 0.6922 - acc: 0.7576 - val_loss: 1.1611 - val_acc: 0.6097
Epoch 28/75
23s - loss: 0.6608 - acc: 0.7698 - val_loss: 1.1598 - val_acc: 0.6133
Epoch 29/75
23s - loss: 0.6279 - acc: 0.7828 - val_loss: 1.1660 - val_acc: 0.6121
Epoch 30/75
23s - loss: 0.5923 - acc: 0.7953 - val_loss: 1.1616 - val_acc: 0.6158
Epoch 31/75
23s - loss: 0.5617 - acc: 0.8064 - val_loss: 1.2023 - val_acc: 0.6103
Epoch 32/75
23s - loss: 0.5295 - acc: 0.8170 - val_loss: 1.1848 - val_acc: 0.6202
Epoch 33/75
23s - loss: 0.4953 - acc: 0.8309 - val_loss: 1.2025 - val_acc: 0.6206
Epoch 34/75
23s - loss: 0.4643 - acc: 0.8395 - val_loss: 1.2353 - val_acc: 0.6144
Epoch 35/75
23s - loss: 0.4378 - acc: 0.8486 - val_loss: 1.2335 - val_acc: 0.6191
Epoch 36/75
23s - loss: 0.4089 - acc: 0.8621 - val_loss: 1.2496 - val_acc: 0.6215
Epoch 37/75
23s - loss: 0.3879 - acc: 0.8674 - val_loss: 1.2632 - val_acc: 0.6239
Epoch 38/75
23s - loss: 0.3572 - acc: 0.8792 - val_loss: 1.2822 - val_acc: 0.6212
Epoch 39/75
23s - loss: 0.3365 - acc: 0.8858 - val_loss: 1.3064 - val_acc: 0.6178
Epoch 40/75
23s - loss: 0.3133 - acc: 0.8943 - val_loss: 1.3171 - val_acc: 0.6235
Epoch 41/75
23s - loss: 0.2971 - acc: 0.9030 - val_loss: 1.3302 - val_acc: 0.6238
Epoch 42/75
23s - loss: 0.2758 - acc: 0.9085 - val_loss: 1.3332 - val_acc: 0.6271
Epoch 43/75
23s - loss: 0.2593 - acc: 0.9134 - val_loss: 1.3509 - val_acc: 0.6239
Epoch 44/75
23s - loss: 0.2423 - acc: 0.9210 - val_loss: 1.3822 - val_acc: 0.6289
Epoch 45/75
23s - loss: 0.2258 - acc: 0.9262 - val_loss: 1.4035 - val_acc: 0.6269
Epoch 46/75
23s - loss: 0.2146 - acc: 0.9299 - val_loss: 1.4127 - val_acc: 0.6271
Epoch 47/75
23s - loss: 0.2006 - acc: 0.9339 - val_loss: 1.4289 - val_acc: 0.6247
Epoch 48/75
23s - loss: 0.1885 - acc: 0.9387 - val_loss: 1.4569 - val_acc: 0.6263
Epoch 49/75
23s - loss: 0.1754 - acc: 0.9445 - val_loss: 1.4814 - val_acc: 0.6259
Epoch 50/75
23s - loss: 0.1625 - acc: 0.9499 - val_loss: 1.4806 - val_acc: 0.6280
Epoch 51/75
23s - loss: 0.1541 - acc: 0.9518 - val_loss: 1.5032 - val_acc: 0.6319
Epoch 52/75
23s - loss: 0.1472 - acc: 0.9532 - val_loss: 1.5168 - val_acc: 0.6309
Epoch 53/75
23s - loss: 0.1397 - acc: 0.9561 - val_loss: 1.5238 - val_acc: 0.6301
Epoch 54/75
23s - loss: 0.1312 - acc: 0.9594 - val_loss: 1.5588 - val_acc: 0.6350
Epoch 55/75
23s - loss: 0.1240 - acc: 0.9611 - val_loss: 1.5617 - val_acc: 0.6306
Epoch 56/75
23s - loss: 0.1151 - acc: 0.9648 - val_loss: 1.5812 - val_acc: 0.6283
Epoch 57/75
23s - loss: 0.1114 - acc: 0.9666 - val_loss: 1.5963 - val_acc: 0.6342
Epoch 58/75
23s - loss: 0.1075 - acc: 0.9662 - val_loss: 1.6130 - val_acc: 0.6313
Epoch 59/75
23s - loss: 0.0980 - acc: 0.9701 - val_loss: 1.6312 - val_acc: 0.6323
Epoch 60/75
23s - loss: 0.0975 - acc: 0.9704 - val_loss: 1.6392 - val_acc: 0.6323
Epoch 61/75
23s - loss: 0.0892 - acc: 0.9730 - val_loss: 1.6673 - val_acc: 0.6290
Epoch 62/75
23s - loss: 0.0896 - acc: 0.9734 - val_loss: 1.6881 - val_acc: 0.6299
Epoch 63/75
23s - loss: 0.0827 - acc: 0.9755 - val_loss: 1.6742 - val_acc: 0.6337
Epoch 64/75
23s - loss: 0.0780 - acc: 0.9775 - val_loss: 1.7100 - val_acc: 0.6328
Epoch 65/75
23s - loss: 0.0766 - acc: 0.9774 - val_loss: 1.7237 - val_acc: 0.6331
Epoch 66/75
23s - loss: 0.0720 - acc: 0.9790 - val_loss: 1.6999 - val_acc: 0.6321
Epoch 67/75
23s - loss: 0.0688 - acc: 0.9804 - val_loss: 1.7270 - val_acc: 0.6345
Epoch 68/75
23s - loss: 0.0667 - acc: 0.9796 - val_loss: 1.7561 - val_acc: 0.6337
Epoch 69/75
23s - loss: 0.0666 - acc: 0.9800 - val_loss: 1.7261 - val_acc: 0.6352
Epoch 70/75
23s - loss: 0.0625 - acc: 0.9826 - val_loss: 1.7724 - val_acc: 0.6350
Epoch 71/75
23s - loss: 0.0587 - acc: 0.9839 - val_loss: 1.7412 - val_acc: 0.6352
Epoch 72/75
23s - loss: 0.0595 - acc: 0.9823 - val_loss: 1.7771 - val_acc: 0.6375
Epoch 73/75
23s - loss: 0.0560 - acc: 0.9843 - val_loss: 1.7912 - val_acc: 0.6356
Epoch 74/75
23s - loss: 0.0548 - acc: 0.9843 - val_loss: 1.7972 - val_acc: 0.6369
Epoch 75/75
23s - loss: 0.0525 - acc: 0.9850 - val_loss: 1.7820 - val_acc: 0.6374
Score:  0.637372525495
acc:      ['0.293', '0.380', '0.419', '0.450', '0.468', '0.487', '0.505', '0.518', '0.536', '0.549', '0.563', '0.572', '0.587', '0.599', '0.613', '0.622', '0.634', '0.647', '0.660', '0.671', '0.682', '0.697', '0.710', '0.720', '0.731', '0.748', '0.758', '0.770', '0.783', '0.795', '0.806', '0.817', '0.831', '0.839', '0.849', '0.862', '0.867', '0.879', '0.886', '0.894', '0.903', '0.909', '0.913', '0.921', '0.926', '0.930', '0.934', '0.939', '0.944', '0.950', '0.952', '0.953', '0.956', '0.959', '0.961', '0.965', '0.967', '0.966', '0.970', '0.970', '0.973', '0.973', '0.975', '0.978', '0.977', '0.979', '0.980', '0.980', '0.980', '0.983', '0.984', '0.982', '0.984', '0.984', '0.985']
val_acc:  ['0.370', '0.409', '0.432', '0.464', '0.478', '0.487', '0.505', '0.511', '0.526', '0.541', '0.542', '0.551', '0.553', '0.561', '0.569', '0.566', '0.573', '0.580', '0.588', '0.587', '0.589', '0.602', '0.590', '0.598', '0.601', '0.607', '0.610', '0.613', '0.612', '0.616', '0.610', '0.620', '0.621', '0.614', '0.619', '0.621', '0.624', '0.621', '0.618', '0.623', '0.624', '0.627', '0.624', '0.629', '0.627', '0.627', '0.625', '0.626', '0.626', '0.628', '0.632', '0.631', '0.630', '0.635', '0.631', '0.628', '0.634', '0.631', '0.632', '0.632', '0.629', '0.630', '0.634', '0.633', '0.633', '0.632', '0.634', '0.634', '0.635', '0.635', '0.635', '0.637', '0.636', '0.637', '0.637']
Running Fold 2 / 2
Train on 33330 samples, validate on 16670 samples
Epoch 1/75
23s - loss: 2.0222 - acc: 0.2739 - val_loss: 1.8743 - val_acc: 0.3418
Epoch 2/75
23s - loss: 1.7687 - acc: 0.3777 - val_loss: 1.7231 - val_acc: 0.3993
Epoch 3/75
23s - loss: 1.6440 - acc: 0.4216 - val_loss: 1.6270 - val_acc: 0.4309
Epoch 4/75
23s - loss: 1.5634 - acc: 0.4472 - val_loss: 1.5379 - val_acc: 0.4596
Epoch 5/75
23s - loss: 1.5035 - acc: 0.4696 - val_loss: 1.5005 - val_acc: 0.4668
Epoch 6/75
23s - loss: 1.4518 - acc: 0.4878 - val_loss: 1.5020 - val_acc: 0.4621
Epoch 7/75
23s - loss: 1.4064 - acc: 0.5029 - val_loss: 1.4134 - val_acc: 0.5029
Epoch 8/75
23s - loss: 1.3578 - acc: 0.5195 - val_loss: 1.3649 - val_acc: 0.5166
Epoch 9/75
23s - loss: 1.3177 - acc: 0.5369 - val_loss: 1.3379 - val_acc: 0.5259
Epoch 10/75
23s - loss: 1.2820 - acc: 0.5486 - val_loss: 1.3095 - val_acc: 0.5389
Epoch 11/75
23s - loss: 1.2461 - acc: 0.5564 - val_loss: 1.3154 - val_acc: 0.5359
Epoch 12/75
23s - loss: 1.2180 - acc: 0.5686 - val_loss: 1.2762 - val_acc: 0.5463
Epoch 13/75
23s - loss: 1.1818 - acc: 0.5851 - val_loss: 1.2626 - val_acc: 0.5557
Epoch 14/75
23s - loss: 1.1533 - acc: 0.5937 - val_loss: 1.2232 - val_acc: 0.5671
Epoch 15/75
23s - loss: 1.1214 - acc: 0.6050 - val_loss: 1.2392 - val_acc: 0.5606
Epoch 16/75
23s - loss: 1.0911 - acc: 0.6172 - val_loss: 1.2109 - val_acc: 0.5759
Epoch 17/75
23s - loss: 1.0599 - acc: 0.6267 - val_loss: 1.1988 - val_acc: 0.5775
Epoch 18/75
23s - loss: 1.0274 - acc: 0.6402 - val_loss: 1.1879 - val_acc: 0.5801
Epoch 19/75
23s - loss: 0.9996 - acc: 0.6491 - val_loss: 1.1720 - val_acc: 0.5834
Epoch 20/75
23s - loss: 0.9674 - acc: 0.6622 - val_loss: 1.1505 - val_acc: 0.5942
Epoch 21/75
23s - loss: 0.9272 - acc: 0.6779 - val_loss: 1.1438 - val_acc: 0.5980
Epoch 22/75
23s - loss: 0.8917 - acc: 0.6914 - val_loss: 1.1374 - val_acc: 0.5999
Epoch 23/75
23s - loss: 0.8558 - acc: 0.7020 - val_loss: 1.1149 - val_acc: 0.6058
Epoch 24/75
23s - loss: 0.8240 - acc: 0.7155 - val_loss: 1.1248 - val_acc: 0.6092
Epoch 25/75
23s - loss: 0.7874 - acc: 0.7266 - val_loss: 1.1196 - val_acc: 0.6091
Epoch 26/75
23s - loss: 0.7548 - acc: 0.7386 - val_loss: 1.1334 - val_acc: 0.6077
Epoch 27/75
23s - loss: 0.7206 - acc: 0.7529 - val_loss: 1.1175 - val_acc: 0.6163
Epoch 28/75
23s - loss: 0.6796 - acc: 0.7668 - val_loss: 1.1173 - val_acc: 0.6185
Epoch 29/75
23s - loss: 0.6489 - acc: 0.7784 - val_loss: 1.1095 - val_acc: 0.6265
Epoch 30/75
23s - loss: 0.6162 - acc: 0.7858 - val_loss: 1.1336 - val_acc: 0.6178
Epoch 31/75
23s - loss: 0.5848 - acc: 0.7992 - val_loss: 1.1301 - val_acc: 0.6301
Epoch 32/75
23s - loss: 0.5500 - acc: 0.8129 - val_loss: 1.1546 - val_acc: 0.6215
Epoch 33/75
23s - loss: 0.5149 - acc: 0.8241 - val_loss: 1.1519 - val_acc: 0.6254
Epoch 34/75
23s - loss: 0.4821 - acc: 0.8357 - val_loss: 1.1597 - val_acc: 0.6285
Epoch 35/75
23s - loss: 0.4552 - acc: 0.8452 - val_loss: 1.1431 - val_acc: 0.6347
Epoch 36/75
23s - loss: 0.4268 - acc: 0.8537 - val_loss: 1.1703 - val_acc: 0.6363
Epoch 37/75
23s - loss: 0.4007 - acc: 0.8634 - val_loss: 1.1923 - val_acc: 0.6362
Epoch 38/75
23s - loss: 0.3694 - acc: 0.8763 - val_loss: 1.2223 - val_acc: 0.6344
Epoch 39/75
23s - loss: 0.3498 - acc: 0.8832 - val_loss: 1.2151 - val_acc: 0.6328
Epoch 40/75
23s - loss: 0.3214 - acc: 0.8923 - val_loss: 1.2280 - val_acc: 0.6391
Epoch 41/75
23s - loss: 0.3051 - acc: 0.9002 - val_loss: 1.2472 - val_acc: 0.6344
Epoch 42/75
23s - loss: 0.2845 - acc: 0.9062 - val_loss: 1.2853 - val_acc: 0.6310
Epoch 43/75
23s - loss: 0.2618 - acc: 0.9153 - val_loss: 1.2868 - val_acc: 0.6385
Epoch 44/75
23s - loss: 0.2426 - acc: 0.9216 - val_loss: 1.3151 - val_acc: 0.6390
Epoch 45/75
23s - loss: 0.2290 - acc: 0.9258 - val_loss: 1.3187 - val_acc: 0.6361
Epoch 46/75
23s - loss: 0.2143 - acc: 0.9316 - val_loss: 1.3447 - val_acc: 0.6395
Epoch 47/75
23s - loss: 0.1969 - acc: 0.9363 - val_loss: 1.3638 - val_acc: 0.6388
Epoch 48/75
23s - loss: 0.1859 - acc: 0.9414 - val_loss: 1.3775 - val_acc: 0.6388
Epoch 49/75
23s - loss: 0.1741 - acc: 0.9459 - val_loss: 1.4082 - val_acc: 0.6386
Epoch 50/75
23s - loss: 0.1620 - acc: 0.9500 - val_loss: 1.3992 - val_acc: 0.6376
Epoch 51/75
23s - loss: 0.1438 - acc: 0.9564 - val_loss: 1.4443 - val_acc: 0.6368
Epoch 52/75
23s - loss: 0.1450 - acc: 0.9550 - val_loss: 1.4725 - val_acc: 0.6374
Epoch 53/75
23s - loss: 0.1369 - acc: 0.9577 - val_loss: 1.4611 - val_acc: 0.6379
Epoch 54/75
23s - loss: 0.1286 - acc: 0.9611 - val_loss: 1.4832 - val_acc: 0.6377
Epoch 55/75
23s - loss: 0.1192 - acc: 0.9634 - val_loss: 1.4847 - val_acc: 0.6419
Epoch 56/75
23s - loss: 0.1138 - acc: 0.9650 - val_loss: 1.5135 - val_acc: 0.6362
Epoch 57/75
23s - loss: 0.1069 - acc: 0.9674 - val_loss: 1.5297 - val_acc: 0.6400
Epoch 58/75
23s - loss: 0.1034 - acc: 0.9698 - val_loss: 1.5402 - val_acc: 0.6397
Epoch 59/75
23s - loss: 0.0985 - acc: 0.9710 - val_loss: 1.5432 - val_acc: 0.6429
Epoch 60/75
23s - loss: 0.0916 - acc: 0.9739 - val_loss: 1.5643 - val_acc: 0.6422
Epoch 61/75
23s - loss: 0.0855 - acc: 0.9757 - val_loss: 1.6170 - val_acc: 0.6417
Epoch 62/75
23s - loss: 0.0809 - acc: 0.9772 - val_loss: 1.5815 - val_acc: 0.6451
Epoch 63/75
23s - loss: 0.0770 - acc: 0.9769 - val_loss: 1.6091 - val_acc: 0.6416
Epoch 64/75
23s - loss: 0.0746 - acc: 0.9783 - val_loss: 1.6100 - val_acc: 0.6409
Epoch 65/75
23s - loss: 0.0699 - acc: 0.9807 - val_loss: 1.6357 - val_acc: 0.6452
Epoch 66/75
23s - loss: 0.0699 - acc: 0.9796 - val_loss: 1.6233 - val_acc: 0.6461
Epoch 67/75
23s - loss: 0.0665 - acc: 0.9815 - val_loss: 1.6617 - val_acc: 0.6419
Epoch 68/75
23s - loss: 0.0607 - acc: 0.9827 - val_loss: 1.6645 - val_acc: 0.6448
Epoch 69/75
23s - loss: 0.0608 - acc: 0.9839 - val_loss: 1.6667 - val_acc: 0.6425
Epoch 70/75
23s - loss: 0.0596 - acc: 0.9829 - val_loss: 1.6880 - val_acc: 0.6458
Epoch 71/75
23s - loss: 0.0520 - acc: 0.9862 - val_loss: 1.6907 - val_acc: 0.6452
Epoch 72/75
23s - loss: 0.0539 - acc: 0.9845 - val_loss: 1.7181 - val_acc: 0.6403
Epoch 73/75
23s - loss: 0.0501 - acc: 0.9866 - val_loss: 1.7146 - val_acc: 0.6429
Epoch 74/75
23s - loss: 0.0507 - acc: 0.9857 - val_loss: 1.7180 - val_acc: 0.6460
Epoch 75/75
23s - loss: 0.0479 - acc: 0.9868 - val_loss: 1.7368 - val_acc: 0.6446
Score:  0.644571085783
acc:      ['0.274', '0.378', '0.422', '0.447', '0.470', '0.488', '0.503', '0.519', '0.537', '0.549', '0.556', '0.569', '0.585', '0.594', '0.605', '0.617', '0.627', '0.640', '0.649', '0.662', '0.678', '0.691', '0.702', '0.716', '0.727', '0.739', '0.753', '0.767', '0.778', '0.786', '0.799', '0.813', '0.824', '0.836', '0.845', '0.854', '0.863', '0.876', '0.883', '0.892', '0.900', '0.906', '0.915', '0.922', '0.926', '0.932', '0.936', '0.941', '0.946', '0.950', '0.956', '0.955', '0.958', '0.961', '0.963', '0.965', '0.967', '0.970', '0.971', '0.974', '0.976', '0.977', '0.977', '0.978', '0.981', '0.980', '0.981', '0.983', '0.984', '0.983', '0.986', '0.985', '0.987', '0.986', '0.987']
val_acc:  ['0.342', '0.399', '0.431', '0.460', '0.467', '0.462', '0.503', '0.517', '0.526', '0.539', '0.536', '0.546', '0.556', '0.567', '0.561', '0.576', '0.578', '0.580', '0.583', '0.594', '0.598', '0.600', '0.606', '0.609', '0.609', '0.608', '0.616', '0.619', '0.627', '0.618', '0.630', '0.622', '0.625', '0.628', '0.635', '0.636', '0.636', '0.634', '0.633', '0.639', '0.634', '0.631', '0.638', '0.639', '0.636', '0.640', '0.639', '0.639', '0.639', '0.638', '0.637', '0.637', '0.638', '0.638', '0.642', '0.636', '0.640', '0.640', '0.643', '0.642', '0.642', '0.645', '0.642', '0.641', '0.645', '0.646', '0.642', '0.645', '0.643', '0.646', '0.645', '0.640', '0.643', '0.646', '0.645']
Running Fold 3 / 2
Train on 33340 samples, validate on 16660 samples
Epoch 1/75
23s - loss: 2.0229 - acc: 0.2721 - val_loss: 1.8539 - val_acc: 0.3486
Epoch 2/75
23s - loss: 1.7752 - acc: 0.3783 - val_loss: 1.7108 - val_acc: 0.4028
Epoch 3/75
23s - loss: 1.6523 - acc: 0.4222 - val_loss: 1.6018 - val_acc: 0.4396
Epoch 4/75
23s - loss: 1.5650 - acc: 0.4483 - val_loss: 1.5340 - val_acc: 0.4682
Epoch 5/75
23s - loss: 1.4960 - acc: 0.4742 - val_loss: 1.4749 - val_acc: 0.4801
Epoch 6/75
23s - loss: 1.4418 - acc: 0.4919 - val_loss: 1.4318 - val_acc: 0.4987
Epoch 7/75
23s - loss: 1.3889 - acc: 0.5101 - val_loss: 1.3912 - val_acc: 0.5152
Epoch 8/75
23s - loss: 1.3387 - acc: 0.5275 - val_loss: 1.3745 - val_acc: 0.5164
Epoch 9/75
23s - loss: 1.2978 - acc: 0.5408 - val_loss: 1.3174 - val_acc: 0.5330
Epoch 10/75
23s - loss: 1.2545 - acc: 0.5593 - val_loss: 1.2876 - val_acc: 0.5444
Epoch 11/75
^CTraceback (most recent call last):
  File "Main2.py", line 135, in <module>
    batch_size=32, verbose=2)
  File "/usr/lib/python3.6/site-packages/keras/models.py", line 870, in fit
    initial_epoch=initial_epoch)
  File "/usr/lib/python3.6/site-packages/keras/engine/training.py", line 1507, in fit
    initial_epoch=initial_epoch)
  File "/usr/lib/python3.6/site-packages/keras/engine/training.py", line 1156, in _fit_loop
    outs = f(ins_batch)
  File "/usr/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2269, in __call__
    **self.session_kwargs)
  File "/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 789, in run
    run_metadata_ptr)
  File "/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 997, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1132, in _do_run
    target_list, options, run_metadata)
  File "/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1139, in _do_call
    return fn(*args)
  File "/usr/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1121, in _run_fn
    status, run_metadata)
KeyboardInterrupt
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Using TensorFlow backend.
(50000, 3072)
(10000, 3072)
(5000, 3072)
9
0
10
Start converting data!
(3750, 32, 32, 3)
(1250, 32, 32, 3)
(3750, 10)
(1250, 10)
10
(50000, 32, 32, 3)
Converting data done!
10
Training network on: 
kernel size: (3, 3)
lrate:       0.0005
dropout:     0.2
dense size:  1024
Running Fold 1 / 2
Train on 33330 samples, validate on 16670 samples
Epoch 1/75
2017-06-18 02:28:00.446096: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.446115: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.446120: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.446123: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.446126: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-18 02:28:00.554759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-18 02:28:00.555178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 750 Ti
major: 5 minor: 0 memoryClockRate (GHz) 1.202
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 3.70GiB
2017-06-18 02:28:00.555192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-18 02:28:00.555196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-18 02:28:00.555202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0)
24s - loss: 1.9831 - acc: 0.2929 - val_loss: 1.8252 - val_acc: 0.3696
Epoch 2/75
23s - loss: 1.7553 - acc: 0.3804 - val_loss: 1.7001 - val_acc: 0.4095
Epoch 3/75
23s - loss: 1.6479 - acc: 0.4195 - val_loss: 1.6288 - val_acc: 0.4317
Epoch 4/75
23s - loss: 1.5632 - acc: 0.4496 - val_loss: 1.5326 - val_acc: 0.4637
Epoch 5/75
23s - loss: 1.5065 - acc: 0.4685 - val_loss: 1.4958 - val_acc: 0.4783
Epoch 6/75
23s - loss: 1.4548 - acc: 0.4872 - val_loss: 1.4654 - val_acc: 0.4875
Epoch 7/75
23s - loss: 1.4082 - acc: 0.5050 - val_loss: 1.4305 - val_acc: 0.5050
Epoch 8/75
23s - loss: 1.3652 - acc: 0.5177 - val_loss: 1.4065 - val_acc: 0.5107
Epoch 9/75
23s - loss: 1.3186 - acc: 0.5363 - val_loss: 1.3554 - val_acc: 0.5258
Epoch 10/75
23s - loss: 1.2777 - acc: 0.5493 - val_loss: 1.3107 - val_acc: 0.5413
Epoch 11/75
23s - loss: 1.2413 - acc: 0.5629 - val_loss: 1.2939 - val_acc: 0.5424
Epoch 12/75
23s - loss: 1.2050 - acc: 0.5716 - val_loss: 1.2813 - val_acc: 0.5509
Epoch 13/75
23s - loss: 1.1689 - acc: 0.5872 - val_loss: 1.2775 - val_acc: 0.5527
Epoch 14/75
23s - loss: 1.1368 - acc: 0.5994 - val_loss: 1.2446 - val_acc: 0.5614
Epoch 15/75
23s - loss: 1.1035 - acc: 0.6127 - val_loss: 1.2291 - val_acc: 0.5693
Epoch 16/75
23s - loss: 1.0730 - acc: 0.6218 - val_loss: 1.2246 - val_acc: 0.5662
Epoch 17/75
23s - loss: 1.0386 - acc: 0.6338 - val_loss: 1.2198 - val_acc: 0.5728
Epoch 18/75
23s - loss: 1.0043 - acc: 0.6475 - val_loss: 1.1921 - val_acc: 0.5804
Epoch 19/75
23s - loss: 0.9723 - acc: 0.6599 - val_loss: 1.1789 - val_acc: 0.5879
Epoch 20/75
23s - loss: 0.9333 - acc: 0.6713 - val_loss: 1.1757 - val_acc: 0.5873
Epoch 21/75
23s - loss: 0.9036 - acc: 0.6818 - val_loss: 1.1841 - val_acc: 0.5887
Epoch 22/75
23s - loss: 0.8686 - acc: 0.6973 - val_loss: 1.1598 - val_acc: 0.6016
Epoch 23/75
23s - loss: 0.8332 - acc: 0.7097 - val_loss: 1.1822 - val_acc: 0.5897
Epoch 24/75
23s - loss: 0.7993 - acc: 0.7201 - val_loss: 1.1761 - val_acc: 0.5977
Epoch 25/75
23s - loss: 0.7636 - acc: 0.7307 - val_loss: 1.1722 - val_acc: 0.6013
Epoch 26/75
23s - loss: 0.7273 - acc: 0.7477 - val_loss: 1.1501 - val_acc: 0.6073
Epoch 27/75
23s - loss: 0.6922 - acc: 0.7576 - val_loss: 1.1611 - val_acc: 0.6097
Epoch 28/75
23s - loss: 0.6608 - acc: 0.7698 - val_loss: 1.1598 - val_acc: 0.6133
Epoch 29/75
23s - loss: 0.6279 - acc: 0.7828 - val_loss: 1.1660 - val_acc: 0.6121
Epoch 30/75
23s - loss: 0.5923 - acc: 0.7953 - val_loss: 1.1616 - val_acc: 0.6158
Epoch 31/75
23s - loss: 0.5617 - acc: 0.8064 - val_loss: 1.2023 - val_acc: 0.6103
Epoch 32/75
23s - loss: 0.5295 - acc: 0.8170 - val_loss: 1.1848 - val_acc: 0.6202
Epoch 33/75
23s - loss: 0.4953 - acc: 0.8309 - val_loss: 1.2025 - val_acc: 0.6206
Epoch 34/75
23s - loss: 0.4643 - acc: 0.8395 - val_loss: 1.2353 - val_acc: 0.6144
Epoch 35/75
23s - loss: 0.4378 - acc: 0.8486 - val_loss: 1.2335 - val_acc: 0.6191
Epoch 36/75
23s - loss: 0.4089 - acc: 0.8621 - val_loss: 1.2496 - val_acc: 0.6215
Epoch 37/75
23s - loss: 0.3879 - acc: 0.8674 - val_loss: 1.2632 - val_acc: 0.6239
Epoch 38/75
23s - loss: 0.3572 - acc: 0.8792 - val_loss: 1.2822 - val_acc: 0.6212
Epoch 39/75
23s - loss: 0.3365 - acc: 0.8858 - val_loss: 1.3064 - val_acc: 0.6178
Epoch 40/75
23s - loss: 0.3133 - acc: 0.8943 - val_loss: 1.3171 - val_acc: 0.6235
Epoch 41/75
23s - loss: 0.2971 - acc: 0.9030 - val_loss: 1.3302 - val_acc: 0.6238
Epoch 42/75
23s - loss: 0.2758 - acc: 0.9085 - val_loss: 1.3332 - val_acc: 0.6271
Epoch 43/75
23s - loss: 0.2593 - acc: 0.9134 - val_loss: 1.3509 - val_acc: 0.6239
Epoch 44/75
23s - loss: 0.2423 - acc: 0.9210 - val_loss: 1.3822 - val_acc: 0.6289
Epoch 45/75
23s - loss: 0.2258 - acc: 0.9262 - val_loss: 1.4035 - val_acc: 0.6269
Epoch 46/75
23s - loss: 0.2146 - acc: 0.9299 - val_loss: 1.4127 - val_acc: 0.6271
Epoch 47/75
23s - loss: 0.2006 - acc: 0.9339 - val_loss: 1.4289 - val_acc: 0.6247
Epoch 48/75
23s - loss: 0.1885 - acc: 0.9387 - val_loss: 1.4569 - val_acc: 0.6263
Epoch 49/75
23s - loss: 0.1754 - acc: 0.9445 - val_loss: 1.4814 - val_acc: 0.6259
Epoch 50/75
23s - loss: 0.1625 - acc: 0.9499 - val_loss: 1.4806 - val_acc: 0.6280
Epoch 51/75
23s - loss: 0.1541 - acc: 0.9518 - val_loss: 1.5032 - val_acc: 0.6319
Epoch 52/75
23s - loss: 0.1472 - acc: 0.9532 - val_loss: 1.5168 - val_acc: 0.6309
Epoch 53/75
23s - loss: 0.1397 - acc: 0.9561 - val_loss: 1.5238 - val_acc: 0.6301
Epoch 54/75
23s - loss: 0.1312 - acc: 0.9594 - val_loss: 1.5588 - val_acc: 0.6350
Epoch 55/75
23s - loss: 0.1240 - acc: 0.9611 - val_loss: 1.5617 - val_acc: 0.6306
Epoch 56/75
23s - loss: 0.1151 - acc: 0.9648 - val_loss: 1.5812 - val_acc: 0.6283
Epoch 57/75
23s - loss: 0.1114 - acc: 0.9666 - val_loss: 1.5963 - val_acc: 0.6342
Epoch 58/75
23s - loss: 0.1075 - acc: 0.9662 - val_loss: 1.6130 - val_acc: 0.6313
Epoch 59/75
23s - loss: 0.0980 - acc: 0.9701 - val_loss: 1.6312 - val_acc: 0.6323
Epoch 60/75
23s - loss: 0.0975 - acc: 0.9704 - val_loss: 1.6392 - val_acc: 0.6323
Epoch 61/75
23s - loss: 0.0892 - acc: 0.9730 - val_loss: 1.6673 - val_acc: 0.6290
Epoch 62/75
23s - loss: 0.0896 - acc: 0.9734 - val_loss: 1.6881 - val_acc: 0.6299
Epoch 63/75
23s - loss: 0.0827 - acc: 0.9755 - val_loss: 1.6742 - val_acc: 0.6337
Epoch 64/75
23s - loss: 0.0780 - acc: 0.9775 - val_loss: 1.7100 - val_acc: 0.6328
Epoch 65/75
23s - loss: 0.0766 - acc: 0.9774 - val_loss: 1.7237 - val_acc: 0.6331
Epoch 66/75
23s - loss: 0.0720 - acc: 0.9790 - val_loss: 1.6999 - val_acc: 0.6321
Epoch 67/75
23s - loss: 0.0688 - acc: 0.9804 - val_loss: 1.7270 - val_acc: 0.6345
Epoch 68/75
23s - loss: 0.0667 - acc: 0.9796 - val_loss: 1.7561 - val_acc: 0.6337
Epoch 69/75
23s - loss: 0.0666 - acc: 0.9800 - val_loss: 1.7261 - val_acc: 0.6352
Epoch 70/75
23s - loss: 0.0625 - acc: 0.9826 - val_loss: 1.7724 - val_acc: 0.6350
Epoch 71/75
23s - loss: 0.0587 - acc: 0.9839 - val_loss: 1.7412 - val_acc: 0.6352
Epoch 72/75
23s - loss: 0.0595 - acc: 0.9823 - val_loss: 1.7771 - val_acc: 0.6375
Epoch 73/75
23s - loss: 0.0560 - acc: 0.9843 - val_loss: 1.7912 - val_acc: 0.6356
Epoch 74/75
23s - loss: 0.0548 - acc: 0.9843 - val_loss: 1.7972 - val_acc: 0.6369
Epoch 75/75
23s - loss: 0.0525 - acc: 0.9850 - val_loss: 1.7820 - val_acc: 0.6374
Score:  0.637372525495
acc:      ['0.293', '0.380', '0.419', '0.450', '0.468', '0.487', '0.505', '0.518', '0.536', '0.549', '0.563', '0.572', '0.587', '0.599', '0.613', '0.622', '0.634', '0.647', '0.660', '0.671', '0.682', '0.697', '0.710', '0.720', '0.731', '0.748', '0.758', '0.770', '0.783', '0.795', '0.806', '0.817', '0.831', '0.839', '0.849', '0.862', '0.867', '0.879', '0.886', '0.894', '0.903', '0.909', '0.913', '0.921', '0.926', '0.930', '0.934', '0.939', '0.944', '0.950', '0.952', '0.953', '0.956', '0.959', '0.961', '0.965', '0.967', '0.966', '0.970', '0.970', '0.973', '0.973', '0.975', '0.978', '0.977', '0.979', '0.980', '0.980', '0.980', '0.983', '0.984', '0.982', '0.984', '0.984', '0.985']
val_acc:  ['0.370', '0.409', '0.432', '0.464', '0.478', '0.487', '0.505', '0.511', '0.526', '0.541', '0.542', '0.551', '0.553', '0.561', '0.569', '0.566', '0.573', '0.580', '0.588', '0.587', '0.589', '0.602', '0.590', '0.598', '0.601', '0.607', '0.610', '0.613', '0.612', '0.616', '0.610', '0.620', '0.621', '0.614', '0.619', '0.621', '0.624', '0.621', '0.618', '0.623', '0.624', '0.627', '0.624', '0.629', '0.627', '0.627', '0.625', '0.626', '0.626', '0.628', '0.632', '0.631', '0.630', '0.635', '0.631', '0.628', '0.634', '0.631', '0.632', '0.632', '0.629', '0.630', '0.634', '0.633', '0.633', '0.632', '0.634', '0.634', '0.635', '0.635', '0.635', '0.637', '0.636', '0.637', '0.637']
Running Fold 2 / 2
Train on 33330 samples, validate on 16670 samples
Epoch 1/75
23s - loss: 2.0222 - acc: 0.2739 - val_loss: 1.8743 - val_acc: 0.3418
Epoch 2/75
23s - loss: 1.7687 - acc: 0.3777 - val_loss: 1.7231 - val_acc: 0.3993
Epoch 3/75
23s - loss: 1.6440 - acc: 0.4216 - val_loss: 1.6270 - val_acc: 0.4309
Epoch 4/75
23s - loss: 1.5634 - acc: 0.4472 - val_loss: 1.5379 - val_acc: 0.4596
Epoch 5/75
23s - loss: 1.5035 - acc: 0.4696 - val_loss: 1.5005 - val_acc: 0.4668
Epoch 6/75
23s - loss: 1.4518 - acc: 0.4878 - val_loss: 1.5020 - val_acc: 0.4621
Epoch 7/75
23s - loss: 1.4064 - acc: 0.5029 - val_loss: 1.4134 - val_acc: 0.5029
Epoch 8/75
23s - loss: 1.3578 - acc: 0.5195 - val_loss: 1.3649 - val_acc: 0.5166
Epoch 9/75
23s - loss: 1.3177 - acc: 0.5369 - val_loss: 1.3379 - val_acc: 0.5259
Epoch 10/75
23s - loss: 1.2820 - acc: 0.5486 - val_loss: 1.3095 - val_acc: 0.5389
Epoch 11/75
23s - loss: 1.2461 - acc: 0.5564 - val_loss: 1.3154 - val_acc: 0.5359
Epoch 12/75
23s - loss: 1.2180 - acc: 0.5686 - val_loss: 1.2762 - val_acc: 0.5463
Epoch 13/75
23s - loss: 1.1818 - acc: 0.5851 - val_loss: 1.2626 - val_acc: 0.5557
Epoch 14/75
23s - loss: 1.1533 - acc: 0.5937 - val_loss: 1.2232 - val_acc: 0.5671
Epoch 15/75
23s - loss: 1.1214 - acc: 0.6050 - val_loss: 1.2392 - val_acc: 0.5606
Epoch 16/75
23s - loss: 1.0911 - acc: 0.6172 - val_loss: 1.2109 - val_acc: 0.5759
Epoch 17/75
23s - loss: 1.0599 - acc: 0.6267 - val_loss: 1.1988 - val_acc: 0.5775
Epoch 18/75
23s - loss: 1.0274 - acc: 0.6402 - val_loss: 1.1879 - val_acc: 0.5801
Epoch 19/75
23s - loss: 0.9996 - acc: 0.6491 - val_loss: 1.1720 - val_acc: 0.5834
Epoch 20/75
23s - loss: 0.9674 - acc: 0.6622 - val_loss: 1.1505 - val_acc: 0.5942
Epoch 21/75
23s - loss: 0.9272 - acc: 0.6779 - val_loss: 1.1438 - val_acc: 0.5980
Epoch 22/75
23s - loss: 0.8917 - acc: 0.6914 - val_loss: 1.1374 - val_acc: 0.5999
Epoch 23/75
23s - loss: 0.8558 - acc: 0.7020 - val_loss: 1.1149 - val_acc: 0.6058
Epoch 24/75
23s - loss: 0.8240 - acc: 0.7155 - val_loss: 1.1248 - val_acc: 0.6092
Epoch 25/75
23s - loss: 0.7874 - acc: 0.7266 - val_loss: 1.1196 - val_acc: 0.6091
Epoch 26/75
23s - loss: 0.7548 - acc: 0.7386 - val_loss: 1.1334 - val_acc: 0.6077
Epoch 27/75
23s - loss: 0.7206 - acc: 0.7529 - val_loss: 1.1175 - val_acc: 0.6163
Epoch 28/75
23s - loss: 0.6796 - acc: 0.7668 - val_loss: 1.1173 - val_acc: 0.6185
Epoch 29/75
23s - loss: 0.6489 - acc: 0.7784 - val_loss: 1.1095 - val_acc: 0.6265
Epoch 30/75
23s - loss: 0.6162 - acc: 0.7858 - val_loss: 1.1336 - val_acc: 0.6178
Epoch 31/75
23s - loss: 0.5848 - acc: 0.7992 - val_loss: 1.1301 - val_acc: 0.6301
Epoch 32/75
23s - loss: 0.5500 - acc: 0.8129 - val_loss: 1.1546 - val_acc: 0.6215
Epoch 33/75
23s - loss: 0.5149 - acc: 0.8241 - val_loss: 1.1519 - val_acc: 0.6254
Epoch 34/75
23s - loss: 0.4821 - acc: 0.8357 - val_loss: 1.1597 - val_acc: 0.6285
Epoch 35/75
23s - loss: 0.4552 - acc: 0.8452 - val_loss: 1.1431 - val_acc: 0.6347
Epoch 36/75
23s - loss: 0.4268 - acc: 0.8537 - val_loss: 1.1703 - val_acc: 0.6363
Epoch 37/75
23s - loss: 0.4007 - acc: 0.8634 - val_loss: 1.1923 - val_acc: 0.6362
Epoch 38/75
23s - loss: 0.3694 - acc: 0.8763 - val_loss: 1.2223 - val_acc: 0.6344
Epoch 39/75
23s - loss: 0.3498 - acc: 0.8832 - val_loss: 1.2151 - val_acc: 0.6328
Epoch 40/75
23s - loss: 0.3214 - acc: 0.8923 - val_loss: 1.2280 - val_acc: 0.6391
Epoch 41/75
23s - loss: 0.3051 - acc: 0.9002 - val_loss: 1.2472 - val_acc: 0.6344
Epoch 42/75
23s - loss: 0.2845 - acc: 0.9062 - val_loss: 1.2853 - val_acc: 0.6310
Epoch 43/75
23s - loss: 0.2618 - acc: 0.9153 - val_loss: 1.2868 - val_acc: 0.6385
Epoch 44/75
23s - loss: 0.2426 - acc: 0.9216 - val_loss: 1.3151 - val_acc: 0.6390
Epoch 45/75
23s - loss: 0.2290 - acc: 0.9258 - val_loss: 1.3187 - val_acc: 0.6361
Epoch 46/75
23s - loss: 0.2143 - acc: 0.9316 - val_loss: 1.3447 - val_acc: 0.6395
Epoch 47/75
23s - loss: 0.1969 - acc: 0.9363 - val_loss: 1.3638 - val_acc: 0.6388
Epoch 48/75
23s - loss: 0.1859 - acc: 0.9414 - val_loss: 1.3775 - val_acc: 0.6388
Epoch 49/75
23s - loss: 0.1741 - acc: 0.9459 - val_loss: 1.4082 - val_acc: 0.6386
Epoch 50/75
23s - loss: 0.1620 - acc: 0.9500 - val_loss: 1.3992 - val_acc: 0.6376
Epoch 51/75
23s - loss: 0.1438 - acc: 0.9564 - val_loss: 1.4443 - val_acc: 0.6368
Epoch 52/75
23s - loss: 0.1450 - acc: 0.9550 - val_loss: 1.4725 - val_acc: 0.6374
Epoch 53/75
23s - loss: 0.1369 - acc: 0.9577 - val_loss: 1.4611 - val_acc: 0.6379
Epoch 54/75
23s - loss: 0.1286 - acc: 0.9611 - val_loss: 1.4832 - val_acc: 0.6377
Epoch 55/75
23s - loss: 0.1192 - acc: 0.9634 - val_loss: 1.4847 - val_acc: 0.6419
Epoch 56/75
23s - loss: 0.1138 - acc: 0.9650 - val_loss: 1.5135 - val_acc: 0.6362
Epoch 57/75
23s - loss: 0.1069 - acc: 0.9674 - val_loss: 1.5297 - val_acc: 0.6400
Epoch 58/75
23s - loss: 0.1034 - acc: 0.9698 - val_loss: 1.5402 - val_acc: 0.6397
Epoch 59/75
23s - loss: 0.0985 - acc: 0.9710 - val_loss: 1.5432 - val_acc: 0.6429
Epoch 60/75
23s - loss: 0.0916 - acc: 0.9739 - val_loss: 1.5643 - val_acc: 0.6422
Epoch 61/75
23s - loss: 0.0855 - acc: 0.9757 - val_loss: 1.6170 - val_acc: 0.6417
Epoch 62/75
23s - loss: 0.0809 - acc: 0.9772 - val_loss: 1.5815 - val_acc: 0.6451
Epoch 63/75
23s - loss: 0.0770 - acc: 0.9769 - val_loss: 1.6091 - val_acc: 0.6416
Epoch 64/75
23s - loss: 0.0746 - acc: 0.9783 - val_loss: 1.6100 - val_acc: 0.6409
Epoch 65/75
23s - loss: 0.0699 - acc: 0.9807 - val_loss: 1.6357 - val_acc: 0.6452
Epoch 66/75
23s - loss: 0.0699 - acc: 0.9796 - val_loss: 1.6233 - val_acc: 0.6461
Epoch 67/75
23s - loss: 0.0665 - acc: 0.9815 - val_loss: 1.6617 - val_acc: 0.6419
Epoch 68/75
23s - loss: 0.0607 - acc: 0.9827 - val_loss: 1.6645 - val_acc: 0.6448
Epoch 69/75
23s - loss: 0.0608 - acc: 0.9839 - val_loss: 1.6667 - val_acc: 0.6425
Epoch 70/75
23s - loss: 0.0596 - acc: 0.9829 - val_loss: 1.6880 - val_acc: 0.6458
Epoch 71/75
23s - loss: 0.0520 - acc: 0.9862 - val_loss: 1.6907 - val_acc: 0.6452
Epoch 72/75
23s - loss: 0.0539 - acc: 0.9845 - val_loss: 1.7181 - val_acc: 0.6403
Epoch 73/75
23s - loss: 0.0501 - acc: 0.9866 - val_loss: 1.7146 - val_acc: 0.6429
Epoch 74/75
23s - loss: 0.0507 - acc: 0.9857 - val_loss: 1.7180 - val_acc: 0.6460
Epoch 75/75
23s - loss: 0.0479 - acc: 0.9868 - val_loss: 1.7368 - val_acc: 0.6446
Score:  0.644571085783
acc:      ['0.274', '0.378', '0.422', '0.447', '0.470', '0.488', '0.503', '0.519', '0.537', '0.549', '0.556', '0.569', '0.585', '0.594', '0.605', '0.617', '0.627', '0.640', '0.649', '0.662', '0.678', '0.691', '0.702', '0.716', '0.727', '0.739', '0.753', '0.767', '0.778', '0.786', '0.799', '0.813', '0.824', '0.836', '0.845', '0.854', '0.863', '0.876', '0.883', '0.892', '0.900', '0.906', '0.915', '0.922', '0.926', '0.932', '0.936', '0.941', '0.946', '0.950', '0.956', '0.955', '0.958', '0.961', '0.963', '0.965', '0.967', '0.970', '0.971', '0.974', '0.976', '0.977', '0.977', '0.978', '0.981', '0.980', '0.981', '0.983', '0.984', '0.983', '0.986', '0.985', '0.987', '0.986', '0.987']
val_acc:  ['0.342', '0.399', '0.431', '0.460', '0.467', '0.462', '0.503', '0.517', '0.526', '0.539', '0.536', '0.546', '0.556', '0.567', '0.561', '0.576', '0.578', '0.580', '0.583', '0.594', '0.598', '0.600', '0.606', '0.609', '0.609', '0.608', '0.616', '0.619', '0.627', '0.618', '0.630', '0.622', '0.625', '0.628', '0.635', '0.636', '0.636', '0.634', '0.633', '0.639', '0.634', '0.631', '0.638', '0.639', '0.636', '0.640', '0.639', '0.639', '0.639', '0.638', '0.637', '0.637', '0.638', '0.638', '0.642', '0.636', '0.640', '0.640', '0.643', '0.642', '0.642', '0.645', '0.642', '0.641', '0.645', '0.646', '0.642', '0.645', '0.643', '0.646', '0.645', '0.640', '0.643', '0.646', '0.645']

Runned 2 folds, Average score 0.6409